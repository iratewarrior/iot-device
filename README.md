# Описание проекта

В настоящем учебном проекте реализована система обработки данных с вымышленных температурных датчиков. Данная система включает в себя следующие компоненты:

1. Продюсер - сервис, написаный на python, основной задачей которого является генерация событий с 10 вымышленных датчиков. Продюсеру соответствует контейнер producer в docker-compose.yml. Постоянные данные датчиков представлены в файле producer/coords.csv (идентификатор, широта и долгота). Каждое событие представляется в виде JSON-объекта, включающего:
* Идентификатор датчика (sensor\_id) - целое число в восьмеричной системе
* Идентификатор контроллера датчика (controller\_id) - Значение sha1-функции от идентификатора датчика
* Широта и долгота датчиков (latitude, longitude) - в пределах России
* Температура (temperature) - целое число от -20 до 20
* Дата и время события (occur\_time)

Продюсер генерирует 10 событий по каждому датчику каждую секунду и передает их в топик "iot" Kafka.

2. Образ Kafka (название контейнера - kafka) - используется образ Kafka от Bitnami (а также образ Zookeeper от Bitnami, название контейнера - kafka), в образе настроен топик "iot", в который пишет Продюсер и из которого читает Консьюмер, описываемый в следующем пункте.

3. Консьюмер (название контейнера - consumer) - сервис, написанный на python, в реальном времени считывает JSON объекты из топика "iot" и записывает их в stg-слой в Greenplum

4. Образ greenplum (название контейнера - greenplum) - используется неофициальный образ Greenplum, подвергшийся модификациям, чтобы позволить создать БД в Greenplum с именем, указанным в .env, таблицы records и filtered\_records, соответствующие stg- и dds-слоям соответственно, пользователя с именем и паролем, указанным в .env, а также позволить дать созданному пользователю права на все действия (в частности, добавление, просмотр и удаление) со слоями stg и dds.

5. Airflow (название контейнера - airflow) - используется базовый образ Ubuntu:22.04, на который устанавливаются пакеты, необходимые для работы Airflow и взаимодействия с greenplum. Airflow используется в проекте для считывания данных из слоя stg раз в минуту и последующей обработки и помещения записей с отфильтрованной температурой (меньше 0 градусов) в слой dds.

6. Jupyter (название контейнера - jupyter) - может быть использован для просмотра dag-ов Airflow, кода producer и consumer, используется официальный образ jupyter/minimal-notebook.

Все указанные контейнеры объединены в сеть внутри Docker, с диапазоном IP-адресов 172.16.0.0/24. В частности, IP-адрес хоста в данной сети - 172.16.0.1. Остальные IP-адреса явно указаны для каждого контейнера.

Ряд контейнеров зависят от корректного запуска и инициализации других контейнеров. Для контроля данной зависимости используется инструкция healthcheck (написана для greenplum и kafka, поскольку их время инициализации достаточно продолжительно; также присутствует healthcheck, встроенный в образ jupyter, который несущественен для работы проекта). Контейнеры, зависящие от greenplum или kafka, имеют соответствующую инструкцию depends\_on, не позволяющую зависимым контейнерам запуститься до успешного результата healthcheck.

# Скачивание и запуск

Порядок действий:
1. Скачать репозиторий

`git clone https://github.com/iratewarrior/iot-device`

2. Перейти в репозиторий

`cd iot-device`

3. Запустить развертку приложений

`docker-compose up -d`

4. После завершения п. 3 следует запустить мониторинг docker-контейнеров
. Мониторинг можно остановить в любой момент комбинацией Ctrl+C

`./ps.sh`

5. Дождаться, пока 3 контейнера (greenplum, jupyter, kafka) перейдут в состояние "healthy". После достижения данного состояния ввести комбинацию Ctrl+C. С системой можно начинать работу.

6. Для удостоверения в работе Airflow следует войти в веб-интерфейс Airflow по адресу https://localhost:8080, (следует проигнорировать предупрежджение браузера о риске использования самоподписанного сертификата; логин и пароль - значения переменных AIRFLOW\_USERNAME, AIRFLOW\_PASSWORD из .env соответственно), перейти в раздел Dags и включить dag с названием dag\_filter, поставив переключатель слева от названия dag в состояние "включено".

# Проверка работы

Конечным результатом проекта является база данных greenplum, с заполняемыми таблицами records (соответствует слою stg) и filtered\_records (соответствует слою dds)

Для проверки работы предлагается использовать утилиту psql в составе Postgresql

Порядок проверки:

1. Подключиться к СУБД Greenplum, введя в терминале Linux ($USERNAME, $DBNAME - имя пользователя и БД из переменной DATABASE\_USERNAME и DATABASE\_NAME в файле .env соответственно):

`psql -U $USERNAME $DBNAME`

2. Будет запрошен пароль - ввести значение переменной DATABASE\_PASSWORD из .env

3. Для проверки наполняемости stg слоя ввести следующую команду. Число записей должно увеличиваться каждую секунду:

`select count(*) from records;`

4. Для проверки наполняемости dds слоя ввести следующую команду. Число записей должно увеличиваться каждую минуту:

`select count(*) from filtered_records;`

5. Для проверки содержимого dds слоя ввести следующую команду. Значения столбца temperature должны быть отрицательными целыми числами от -20 до -1:

`select * from filtered_records;`

# Минимальные системные требования

* Intel Core i3-9100 3.60GHz
* 8ГБ RAM
* 8ГБ на твердотельном накопителе (SSD)

# Требуемое программное обеспечение

* Git 2.38.1+
* Docker 20.10.21+
* Docker-Compose 1.29.2+
* Firefox 107.0.1+ или Google Chrome 107.0.5304.122-1.1+
* Postgresql 14.3+ (требуется только для проверки результата)
